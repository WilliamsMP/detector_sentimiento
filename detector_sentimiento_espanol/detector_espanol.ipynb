{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, data reading, feature engineering, hyperparameter selection and model training are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xml.dom import minidom\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data is assigned to a variable and combined into a tuple called path_list.\n",
    "xml format files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_es = 'ES_train.xml'\n",
    "path_mx = 'MX_train.xml'\n",
    "path_pe = 'PE_train.xml'\n",
    "path_uy = 'UY_train.xml'\n",
    "\n",
    "path_list  = (path_es, path_mx, path_pe, path_uy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido = []\n",
    "sentimiento = []\n",
    "def contenido_atributos(path_list):\n",
    "\n",
    "    '''Function to extract the comment and the \n",
    "        sentiment of each one.\n",
    "    \n",
    "    Parameters:\n",
    "        path_list: is a list or tuple.\n",
    "    \n",
    "    Return:\n",
    "        returns the comment and the sentiment in two \n",
    "        different variables of all the data.\n",
    "    \n",
    "    '''\n",
    "    for i in path_list:\n",
    "        mydoc = minidom.parse(i)\n",
    "        content = mydoc.getElementsByTagName('content')\n",
    "        sentiment = mydoc.getElementsByTagName('value')\n",
    "\n",
    "        for element in content:\n",
    "            contenido.append(element.firstChild.data)\n",
    "        for element in sentiment:\n",
    "            sentimiento.append(element.firstChild.data)\n",
    "    \n",
    "    return contenido, sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido, sentimiento = contenido_atributos(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contenido), len(sentimiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two variables with the comment and the sentiment are merged into a single list called datos_totales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datos_totales=[]\n",
    "for i in zip(contenido, sentimiento):\n",
    "    datos_totales.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datos_totales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_totales[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contenido[5], sentimiento[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the list into a dataframe to work more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(datos_totales)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We renamed the columns for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0: 'comentario', 1:'sentimiento'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentimiento'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four different sentiment categories, but we are only going to work with two of them, N and P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df['sentimiento']=='NEU') | (df['sentimiento']=='NONE')).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[(df['sentimiento']=='P') | (df['sentimiento']=='N')]\n",
    "df_final['sentimiento'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the categories N by 0 and P by 1 for a better understanding of the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['sentimiento'] = df_final['sentimiento'].replace({'P': 1}) \n",
    "df_final['sentimiento'] = df_final['sentimiento'].replace({'N': 0})\n",
    "df_final['sentimiento'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final dataframe ready to process in the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comentario = df_final['comentario']\n",
    "df_sentimiento = df_final['sentimiento']\n",
    "df_comentario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_comentario is our X, and df_sentimiento is our Y. We separate them into 85% training data and 15% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_comentario, df_sentimiento, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer is used to work with text type data, which is ideal for a classification problem. For more detailed information consult documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizacion = TfidfVectorizer(ngram_range=(1,1))\n",
    "train_x_vect = vectorizacion.fit_transform(X_train)\n",
    "test_x_vect = vectorizacion.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use SVM for this classification problem, more information about this and other classification models, consult the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "grid_svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(train_x_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.score(test_x_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, svc.predict(test_x_vect), average=None, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = ['tus maquinas 3d no tienen niun brillo maldito surenio', 'era mentira te quiero mucho uwu']\n",
    "prueba_transformado = vectorizacion.transform(prueba)\n",
    "\n",
    "svc.predict(prueba_transformado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, evaluated and seeing results, we look for the best hyperparameters to increase performance with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parametros = {\n",
    "    'kernel': ('linear', 'rbf', 'poly'),\n",
    "    'C': [0.001, 0.01, 0.1, 10],\n",
    "    'gamma': ('scale', 'auto')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final = GridSearchCV(grid_svc, parametros, cv=5, scoring='roc_auc')\n",
    "svc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final.fit(train_x_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_final.score(test_x_vect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significantly increased performance after tuning hyperparameters from 75% to 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, svc_final.predict(test_x_vect), average=None, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, svc_final.predict(test_x_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svc_final.predict(test_x_vect), labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using different evaluation metrics we achieve the following performance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## positivo 1, negativo 0\n",
    "prueba = ['parece cualquer cosa menos persona']\n",
    "prueba_transformado = vectorizacion.transform(prueba)\n",
    "\n",
    "svc_final.predict(prueba_transformado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exportando el mejor modelo\n",
    "joblib.dump(svc_final, 'best_model_espanol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importando el mejor meodelo\n",
    "model = joblib.load('best_model_espanol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## positivo 1, negativo 0\n",
    "prueba = ['ojala todos fueran asi de buenos']\n",
    "prueba_transformado = vectorizacion.transform(prueba)\n",
    "\n",
    "#model.predict(prueba_transformado)\n",
    "resultado = model.predict(prueba_transformado)\n",
    "\n",
    "if resultado == 1: \n",
    "    print('Positivo') \n",
    "else: print('Negativo') #resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(vectorizacion, 'vect_fit_espanol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativo\n"
     ]
    }
   ],
   "source": [
    "## importa libreria\n",
    "import joblib \n",
    "\n",
    "## importando el mejor meodelo y vectorizador\n",
    "model = joblib.load('best_model_espanol')\n",
    "vectorizacion_espanol = joblib.load('vect_fit_espanol')\n",
    "\n",
    "## lista de frases para aplicar prediccion\n",
    "prueba = ['no sabes nada']\n",
    "prueba_transformado = vectorizacion_espanol.transform(prueba)\n",
    "\n",
    "## prediccion del modelo\n",
    "resultado = model.predict(prueba_transformado)\n",
    "\n",
    "if resultado == 1: \n",
    "    print('Positivo') \n",
    "else: \n",
    "    print('Negativo') "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1870f1194fb5b3d43b6d32e845741389586dbe9c4e1e45e17e0f6602cfe22778"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
